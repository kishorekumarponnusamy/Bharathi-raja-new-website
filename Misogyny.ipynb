{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kishorekumarponnusamy/Bharathi-raja-new-website/blob/master/Misogyny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4MsR50PoXb6",
        "outputId": "3c5d4774-2e8d-49c5-d7a1-6c8b1978fe2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m286.7/981.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m890.9/981.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=97acfcafc193b4c109449a4dac519ce7e8e5648e606eb1b7c4344d4acf6651e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM2moLlaSEut",
        "outputId": "e3f956cd-b4c6-47c0-9498-d2175aa3e96a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wGj6O1LclmX"
      },
      "source": [
        "# youtube scraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPueUhOBE8wO",
        "outputId": "eb77a86c-8c46-47ad-d221-5075ddc85a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "pip install requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfisIeVhE8p2",
        "outputId": "2003ccd6-90e0-4c6f-c119-a69135ff02c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "pip install beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oFjq5CmC2xK",
        "outputId": "2895038d-136b-4df8-d185-fe6246bd0f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo8ezoA8SFZg",
        "outputId": "02b0db38-d0b1-4071-eec0-84b82b079441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting youtube-comment-downloader\n",
            "  Downloading youtube_comment_downloader-0.1.70-py3-none-any.whl (7.9 kB)\n",
            "Collecting dateparser (from youtube-comment-downloader)\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-comment-downloader) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader) (2023.3.post1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader) (2023.6.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader) (5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->dateparser->youtube-comment-downloader) (1.16.0)\n",
            "Installing collected packages: dateparser, youtube-comment-downloader\n",
            "Successfully installed dateparser-1.2.0 youtube-comment-downloader-0.1.70\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-comment-downloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEEmAQQkSLo0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from youtube_comment_downloader import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTcUFnmZSLll"
      },
      "outputs": [],
      "source": [
        "# ytb_video_list = ['https://youtu.be/IIOPmtuLiMQ', 'https://youtu.be/4pURfNJJ9Qw', 'https://youtu.be/NlO7u4uhytE', 'https://youtu.be/1-rcmc8w6uU', 'https://youtu.be/7iY649jHtnI', 'https://youtu.be/CYOzxG3NazE', 'https://youtu.be/0t_m7vOYwFs', 'https://youtu.be/tA4z2_RDuNY', 'https://youtu.be/G3nHLpgG83c','https://youtu.be/Jrj0RYOj4aI', 'https://youtu.be/TinzHl_NuhU']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCktMQCxxMU7"
      },
      "outputs": [],
      "source": [
        " ytb_video_list = ['https://youtu.be/bOUkpwv1AFE?feature=shared', 'https://youtu.be/sSUdKqTyh0M?feature=shared', 'https://youtu.be/C8kPo2ykq0I?feature=shared', 'https://youtu.be/oIxqmFXNSxE?feature=shared' , 'https://youtu.be/6ow7jiDabh4?feature=shared', 'https://youtu.be/glM8N30Xfew?feature=shared', 'https://youtu.be/26v_tQsr-a8?feature=shared', 'https://youtu.be/ZPPurHydl6U?feature=shared' ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlQPigPqY0EA"
      },
      "outputs": [],
      "source": [
        "# ytb_video_list = ['https://youtube.com/shorts/SsgmKcWW0kY?feature=share', 'https://youtube.com/shorts/cSaFR70mK6k?feature=share', 'https://youtube.com/shorts/rt_RjaARIMs?feature=share', 'https://youtube.com/shorts/59a4ntyYxhQ?feature=share']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSH21EccydJA"
      },
      "outputs": [],
      "source": [
        "#, 'https://youtu.be/-ti_ceYi3eg?feature=shared'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKBEopJaCQCZ"
      },
      "source": [
        "## Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT6BSXE6SLh3"
      },
      "outputs": [],
      "source": [
        "def vid_id_separator(ytb_video_list):\n",
        "  list1=[]\n",
        "  for item in ytb_video_list:\n",
        "    if re.search('youtu.be',item):\n",
        "      item_list=item.split('/')\n",
        "      list1.append(item_list[3])\n",
        "    if re.search('www.youtube.com',item):\n",
        "      item_list=item.split('v=')\n",
        "      list1.append(item_list[1])\n",
        "  return list1\n",
        "def cmt_dow(list1):\n",
        "  for item in list1:\n",
        "    !youtube-comment-downloader --youtubeid {item} --output {item}.json\n",
        "def csv_ext(id_list):\n",
        "  df=pd.DataFrame()\n",
        "  fname=[]\n",
        "  for item in id_list:\n",
        "    ll=item+'.json'\n",
        "    fname.append(ll)\n",
        "  for fname in fname:\n",
        "    with open(fname, \"r\") as a_file:\n",
        "      for line in a_file:\n",
        "        res = json.loads(line)\n",
        "        list_s=[res['text']]\n",
        "        list_s=pd.DataFrame(list_s)\n",
        "        df=pd.concat([df,list_s])\n",
        "    # type(list_s)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrwHyZr7SLec"
      },
      "outputs": [],
      "source": [
        "def final_function(ytb_video_list):\n",
        "  inp1=vid_id_separator(ytb_video_list)\n",
        "  inp2=cmt_dow(inp1)\n",
        "  inp3=csv_ext(inp1)\n",
        "  return inp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdNHDHboSLbi",
        "outputId": "2f6cd60c-4a02-486f-9dc1-9f928ee5ef61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Youtube comments for bOUkpwv1AFE?feature=shared\n",
            "Downloaded 1391 comment(s)\n",
            "[32.51 seconds] Done!\n",
            "Downloading Youtube comments for sSUdKqTyh0M?feature=shared\n",
            "Downloaded 1511 comment(s)\n",
            "[27.33 seconds] Done!\n",
            "Downloading Youtube comments for C8kPo2ykq0I?feature=shared\n",
            "Downloaded 970 comment(s)\n",
            "[23.58 seconds] Done!\n",
            "Downloading Youtube comments for oIxqmFXNSxE?feature=shared\n",
            "Downloaded 889 comment(s)\n",
            "[20.66 seconds] Done!\n",
            "Downloading Youtube comments for 6ow7jiDabh4?feature=shared\n",
            "Downloaded 1 comment(s)\n",
            "[0.29 seconds] Done!\n",
            "Downloading Youtube comments for glM8N30Xfew?feature=shared\n",
            "Downloaded 1156 comment(s)\n",
            "[31.16 seconds] Done!\n",
            "Downloading Youtube comments for 26v_tQsr-a8?feature=shared\n",
            "Downloaded 1374 comment(s)\n",
            "[37.39 seconds] Done!\n",
            "Downloading Youtube comments for ZPPurHydl6U?feature=shared\n",
            "Downloaded 406 comment(s)\n",
            "[11.03 seconds] Done!\n"
          ]
        }
      ],
      "source": [
        "df1=final_function(ytb_video_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwJJr1MOS5TS",
        "outputId": "e23f024d-f187-47c3-a677-f72109ea1135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                    0\n",
            "0                  Ean manasula ulla bharamea pochuğŸ˜…ğŸ˜…\n",
            "0   Basic house hold chores ah share pannikirathul...\n",
            "0   eppa lam washing machine la poduradhu illa bro...\n",
            "0                                    U r that boomaru\n",
            "0                bro lost all my respect w this video\n",
            "..                                                ...\n",
            "0                                    Irritating girls\n",
            "0              Intha ponnunga pesurathu kaddupa iruku\n",
            "0   Ithela paathutu ivala marg pandran paaru avana...\n",
            "0   Ama bro. Asingame ilama amma appa nala mudiyat...\n",
            "0                                                 Yes\n",
            "\n",
            "[7697 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGxUEzQUSLX2"
      },
      "outputs": [],
      "source": [
        "df1.to_csv('/content/drive/MyDrive/Misogyny/Misogyny/new.csv',index=False, header=['texts'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gXZbt_kCUPb"
      },
      "source": [
        "## Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPSHndWwCT5w"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "# import pandas as pd\n",
        "\n",
        "# # Get the YouTube video URL\n",
        "# video_url = [\n",
        "#     \"https://youtu.be/bOUkpwv1AFE?feature=shared\",\n",
        "#     \"https://youtu.be/sSUdKqTyh0M?feature=shared\",\n",
        "#     \"https://youtu.be/-ti_ceYi3eg?feature=shared\",\n",
        "#     \"https://youtu.be/C8kPo2ykq0I?feature=shared\",\n",
        "#     \"https://youtu.be/oIxqmFXNSxE?feature=shared\" ,\n",
        "#     \"https://youtu.be/6ow7jiDabh4?feature=shared\",\n",
        "#     \"https://youtu.be/glM8N30Xfew?feature=shared\",\n",
        "#     \"https://youtu.be/26v_tQsr-a8?feature=shared\",\n",
        "#     \"https://youtu.be/ZPPurHydl6U?feature=shared\"\n",
        "#     ]\n",
        "\n",
        "# # Make a request to the video URL\n",
        "# response = requests.get(video_url)\n",
        "\n",
        "# # Parse the response using BeautifulSoup\n",
        "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# # Find all the comment elements\n",
        "# comments = soup.find_all(\"ytd-comment-renderer\")\n",
        "\n",
        "# # Create a list to store the comment data\n",
        "# comment_data = []\n",
        "\n",
        "# # Iterate over the comments and extract the data\n",
        "# for comment in comments:\n",
        "#     text = comment.find(\"yt-formatted-string\", class_=\"style-scope ytd-comment-renderer\").text\n",
        "#     comment_data.append([text])\n",
        "\n",
        "# # Create a Pandas DataFrame from the comment data\n",
        "# df = pd.DataFrame(comment_data, columns=[\"texts\"])\n",
        "\n",
        "# # Save the DataFrame to a CSV file\n",
        "# df.to_csv('/content/drive/MyDrive/Misogyny/comments.csv',index=False,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK_N9WWxIhl3"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Create a list to store the video URLs\n",
        "video_urls = [\n",
        "    \"https://youtu.be/bOUkpwv1AFE?feature=shared\",\n",
        "    \"https://youtu.be/sSUdKqTyh0M?feature=shared\",\n",
        "    \"https://youtu.be/-ti_ceYi3eg?feature=shared\",\n",
        "    \"https://youtu.be/C8kPo2ykq0I?feature=shared\",\n",
        "    \"https://youtu.be/oIxqmFXNSxE?feature=shared\" ,\n",
        "    \"https://youtu.be/6ow7jiDabh4?feature=shared\",\n",
        "    \"https://youtu.be/glM8N30Xfew?feature=shared\",\n",
        "    \"https://youtu.be/26v_tQsr-a8?feature=shared\",\n",
        "    \"https://youtu.be/ZPPurHydl6U?feature=shared\"\n",
        "    ]\n",
        "\n",
        "# Create a list to store the comment data for all the videos\n",
        "comment_data = []\n",
        "\n",
        "# Iterate over the video URLs and scrape the comments for each video\n",
        "for video_url in video_urls:\n",
        "\n",
        "    # Make a request to the video URL\n",
        "    response = requests.get(video_url)\n",
        "\n",
        "    # Parse the response using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find all the comment elements\n",
        "    comments = soup.find_all(\"ytd-comment-renderer\")\n",
        "\n",
        "    # Iterate over the comments and extract the data\n",
        "    for comment in comments:\n",
        "        text = comment.find(\"yt-formatted-string\", class_=\"style-scope ytd-comment-renderer\").text\n",
        "        comment_data.append([text])\n",
        "\n",
        "# Create a Pandas DataFrame from the comment data\n",
        "df = pd.DataFrame(comment_data, columns=[\"Comment\"])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "# df = df.to_csv('/content/drive/MyDrive/Misogyny/comments.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olgpQHdoSLUo",
        "outputId": "6e038573-d2b8-494a-9489-b739ebb39b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Comment]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwuVHae5mLX4"
      },
      "source": [
        "# Text PreProcessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S5iSQVimKJ4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "# from langdetect import detect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAVK-JRVyM2X"
      },
      "source": [
        "## Removing the words less than 5\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzMnnyoUewln"
      },
      "source": [
        "### Storing the less than 5 words\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALyNG3ND6i43"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file, skipping the first column during reading and not considering it as an index\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_text_data.csv\")\n",
        "\n",
        "# Get the texts column (which is now the first column)\n",
        "texts = df[\"texts\"]\n",
        "\n",
        "# Create an empty list to store the filtered texts\n",
        "less5_texts = []\n",
        "\n",
        "# For each text\n",
        "for text in texts:\n",
        "\n",
        "    # Check if the text is not NaN\n",
        "    if pd.notna(text):\n",
        "\n",
        "        # Split the text into words\n",
        "        words = text.split(\" \")\n",
        "\n",
        "        # Check if the number of words is less than 5\n",
        "        if len(words) < 5:\n",
        "\n",
        "            # Add the text to the filtered list\n",
        "            less5_texts.append(text)\n",
        "\n",
        "# Create a new DataFrame with filtered texts\n",
        "filtered_df = pd.DataFrame(less5_texts, columns=[\"texts\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQty3cinfPIl",
        "outputId": "d1423df1-2366-43cb-d989-1f88a4a48428"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25457"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx29ACQqfYKF",
        "outputId": "b2f6eb20-0b4d-4465-9e91-dc835529aa93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   texts\n",
            "0                      Marana kalai.... super editing...\n",
            "1                                  Sunderji very sad men\n",
            "2                                             Kusu.. Ppu\n",
            "3                                      Tevidiya kooshboo\n",
            "4      Super jokes https://youtube.com/shorts/b7lD7Dt...\n",
            "...                                                  ...\n",
            "25452                                    Chiiiii kevalam\n",
            "25453                               Enna karumam da ethu\n",
            "25454                          Unnoda husband oru broker\n",
            "25455                                         TAMILNAADU\n",
            "25456                                                 Hi\n",
            "\n",
            "[25457 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd-NJDBTfgYh"
      },
      "outputs": [],
      "source": [
        "filtered_df.to_csv('/content/drive/MyDrive/Misogyny/Misogyny/merged_less5text_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwyvTTB1e6uU"
      },
      "source": [
        "### Storing the greater than 5 words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7YUqo3xCB8S"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file, skipping the first column during reading and not considering it as an index\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_text_data.csv\")\n",
        "\n",
        "# Get the texts column (which is now the first column)\n",
        "texts = df[\"texts\"]\n",
        "\n",
        "# Create an empty list to store the filtered texts\n",
        "less5_texts = []\n",
        "\n",
        "# For each text\n",
        "for text in texts:\n",
        "\n",
        "    # Check if the text is not NaN\n",
        "    if pd.notna(text):\n",
        "\n",
        "        # Split the text into words\n",
        "        words = text.split(\" \")\n",
        "\n",
        "        # Check if the number of words is less than 5\n",
        "        if len(words) > 5:\n",
        "\n",
        "            # Add the text to the filtered list\n",
        "            less5_texts.append(text)\n",
        "\n",
        "# Create a new DataFrame with filtered texts\n",
        "filtered_df = pd.DataFrame(less5_texts, columns=[\"texts\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuQqxq0MeSZ_",
        "outputId": "2e071070-6c9d-4142-e528-4bd80f75f228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   texts\n",
            "0      Pinnadi irukiravan etho un pinadi parthutu irk...\n",
            "1      à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...\n",
            "2      Anti Muslim bjp party eppadi like panringe kus...\n",
            "3      August 15 .2022 à®‡à®©à¯à®±à¯ à®•à¯à®·à¯à®ªà¯‚ ...à®à®¨à¯à®¤ à®•à®Ÿà¯à®šà®¿à®¯à®¿à®²à¯...\n",
            "4                 Appo enna dash ku congress poi serndha\n",
            "...                                                  ...\n",
            "43638     à®‡à®¨à¯à®¤ à®•à®¾à®²à®¤à¯à®¤à¯ à®ªà®šà®™à¯à®•à®³à¯ˆ à®¨à®¿à®©à¯ˆà®šà¯à®šà®¾ à®•à®·à¯à®Ÿà®®à®¾ à®‡à®°à¯à®•à¯à®•à¯ .\n",
            "43639   Shakeela Amma à®¨à¯€à®™à¯à®• à®…à®µà®™à¯à®•à®³ à®¨à®²à¯à®²à®¾ handle à®ªà®£à¯à®±à¯€à®™à¯à®•\n",
            "43640        à®‡à®¨à¯à®¤ à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®à®©à¯à®©à¯‹à®Ÿ à®µà®¾à®´à¯à®¤à¯à®¤à¯à®•à¯à®•à®³à¯\n",
            "43641  Trichyb sathana..evalam oru pombala..panradhu ...\n",
            "43642              Shakkela amma va pakkanum pola irukku\n",
            "\n",
            "[43643 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0LY8P0teWmB",
        "outputId": "2c681c19-b572-4f88-e6a9-3f9c3b502407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43643"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgMhVwNZfBGc"
      },
      "outputs": [],
      "source": [
        "# Save the filtered DataFrame to a new CSV file\n",
        "filtered_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_greater5text_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOyq83vZyun1"
      },
      "source": [
        "\n",
        "\n",
        "## Removing the emojis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7of8fY6W9g6i",
        "outputId": "982a0d50-28ad-4f56-81e0-cd73a50b8980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas emoji\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNwEYM3CvqxQ",
        "outputId": "58c82666-6777-451c-a10b-e4f1b33f45a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting demoji\n",
            "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: demoji\n",
            "Successfully installed demoji-1.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install demoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KRUJ_0Ag3Mp"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import emoji\n",
        "# import re\n",
        "\n",
        "# # Read the CSV file\n",
        "# df1 = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/data1.csv\")\n",
        "\n",
        "# def remove_emojis(text):\n",
        "#     emoji_pattern = re.compile(\"[\"\n",
        "#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "#                                u\"\\U00002702-\\U000027B0\"\n",
        "#                                u\"\\U000024C2-\\U0001F251\"\n",
        "#                                \"]+\", flags=re.UNICODE)\n",
        "#     removed_emojis = emoji_pattern.findall(text)  # Find all emojis in the text\n",
        "#     clean_text = emoji_pattern.sub(r'', text)  # Remove emojis from the text\n",
        "#     return clean_text, removed_emojis\n",
        "\n",
        "# # Create lists to store cleaned texts and removed emojis\n",
        "# cleaned_texts = []\n",
        "# removed_emojis_list = []\n",
        "\n",
        "# # Process each row in the DataFrame\n",
        "# for index, row in df1.iterrows():\n",
        "#     cleaned_text, removed_emojis = remove_emojis(row['texts'])\n",
        "#     cleaned_texts.append(cleaned_text)\n",
        "#     removed_emojis_str = ' '.join(removed_emojis)  # Join the list of emojis into a single string\n",
        "#     removed_emojis_list.append(removed_emojis_str)\n",
        "\n",
        "# # Convert the lists to DataFrames\n",
        "# cleaned_texts_df = pd.DataFrame(cleaned_texts, columns=['cleaned_texts'])\n",
        "# removed_emojis_df = pd.DataFrame(removed_emojis_list, columns=['removed_emojis'])\n",
        "\n",
        "# # Write DataFrames to CSV files\n",
        "# cleaned_texts_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/data1_emojis.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o67y53XDjpsE"
      },
      "source": [
        "### remove the emoji and store it in seperate file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tST055zMhxxu"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import emoji\n",
        "# import re\n",
        "# import numpy as np\n",
        "\n",
        "# # Read the CSV file\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_data.csv\")\n",
        "\n",
        "# def remove_emojis(text):\n",
        "#     emoji_pattern = re.compile(\"[\"\n",
        "#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "#                                u\"\\U00002702-\\U000027B0\"\n",
        "#                                u\"\\U000024C2-\\U0001F251\"\n",
        "#                                \"]+\", flags=re.UNICODE)\n",
        "#     removed_emojis = emoji_pattern.findall(text)  # Find all emojis in the text\n",
        "#     clean_text = emoji_pattern.sub(r'', text)  # Remove emojis from the text\n",
        "#     return clean_text, removed_emojis\n",
        "\n",
        "# # Create lists to store cleaned texts and removed emojis\n",
        "# cleaned_texts = []\n",
        "# removed_emojis_list = []\n",
        "\n",
        "# # Process each row in the DataFrame\n",
        "# for index, row in df1.iterrows():\n",
        "#     cleaned_text, removed_emojis = remove_emojis(row['texts'])\n",
        "\n",
        "#     # Check if cleaned text is not NaN\n",
        "#     if not pd.isna(cleaned_text):\n",
        "#         cleaned_texts.append(cleaned_text)\n",
        "#     else:\n",
        "#         cleaned_texts.append(\"\")  # Append an empty string if cleaned text is NaN\n",
        "\n",
        "#     removed_emojis_str = ' '.join(removed_emojis) if removed_emojis else np.nan  # Convert empty list to NaN\n",
        "#     removed_emojis_list.append(removed_emojis_str)\n",
        "\n",
        "# # Convert the lists to DataFrames\n",
        "# cleaned_texts_df = pd.DataFrame(cleaned_texts, columns=['texts'])\n",
        "# removed_emojis_df = pd.DataFrame(removed_emojis_list, columns=['emojis'])\n",
        "\n",
        "# # Remove rows with NaN values in \"emojis\" column\n",
        "# removed_emojis_df.dropna(subset=['emojis'], inplace=True)\n",
        "\n",
        "# # Write DataFrames to CSV files\n",
        "# removed_emojis_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_emoji_data.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWcaOv6Slt0g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import emoji\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_data.csv\")\n",
        "\n",
        "def remove_emojis(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    removed_emojis = emoji_pattern.findall(text)  # Find all emojis in the text\n",
        "    return removed_emojis\n",
        "\n",
        "# Create a list to store removed emojis\n",
        "removed_emojis_list = []\n",
        "\n",
        "# Process each row in the DataFrame\n",
        "for index, row in df1.iterrows():\n",
        "    removed_emojis = remove_emojis(row['texts'])\n",
        "\n",
        "    # Append the list of removed emojis to removed_emojis_list\n",
        "    if removed_emojis:\n",
        "        removed_emojis_str = ' '.join(removed_emojis)\n",
        "        removed_emojis_list.append(removed_emojis_str)\n",
        "    else:\n",
        "        removed_emojis_list.append(np.nan)  # Append NaN if no emojis were removed\n",
        "\n",
        "# Convert the list to a DataFrame\n",
        "removed_emojis_df = pd.DataFrame(removed_emojis_list, columns=['emojis'])\n",
        "\n",
        "# Remove rows with NaN values in \"emojis\" column\n",
        "removed_emojis_df.dropna(subset=['emojis'], inplace=True)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "removed_emojis_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_emoji_data.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mYqV-NmqP_I",
        "outputId": "3293f12e-2213-4190-a3c3-5cfd02bca592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   texts\n",
            "0                           Don't stop making videos bro\n",
            "1      Pinnadi irukiravan etho un pinadi parthutu irk...\n",
            "2                 Marana kalai.... â¤ğŸ˜‚ğŸ˜‚ğŸ˜‚ super editing...\n",
            "3      à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...\n",
            "4                                  Sunderji very sad men\n",
            "...                                                  ...\n",
            "78887   Shakeela Amma à®¨à¯€à®™à¯à®• à®…à®µà®™à¯à®•à®³ à®¨à®²à¯à®²à®¾ handle à®ªà®£à¯à®±à¯€à®™à¯à®•\n",
            "78888        à®‡à®¨à¯à®¤ à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®à®©à¯à®©à¯‹à®Ÿ à®µà®¾à®´à¯à®¤à¯à®¤à¯à®•à¯à®•à®³à¯\n",
            "78889  Trichyb sathana..evalam oru pombala..panradhu ...\n",
            "78890              Shakkela amma va pakkanum pola irukku\n",
            "78891                                                 Hi\n",
            "\n",
            "[78892 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9BXoJrYuNT3",
        "outputId": "db2c9261-9977-4525-db98-de64af9d74fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               emojis\n",
            "2                â¤ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
            "5      ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™\n",
            "13                 ğŸ˜…ğŸ˜…\n",
            "16         ğŸ˜‚ ğŸ˜‚ğŸ˜‚ ğŸ˜‚ğŸ˜‚ğŸ˜‚ ğŸ˜‚\n",
            "17        ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ ğŸ‘\n",
            "...               ...\n",
            "20556           âœï¸ â˜ªï¸\n",
            "20569             ğŸ˜‚ ğŸ˜‚\n",
            "20570               ğŸ˜‚\n",
            "20571             â¤â¤â¤\n",
            "20572               ğŸ˜‚\n",
            "\n",
            "[6288 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(removed_emojis_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPkYUFMyj4vL"
      },
      "source": [
        "### without emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktAQ7Ebyj32W"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import re\n",
        "\n",
        "# # Read the CSV file\n",
        "# df1 = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_data.csv\")\n",
        "\n",
        "# def remove_emojis(text):\n",
        "#     emoji_pattern = re.compile(\"[\"\n",
        "#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "#                                u\"\\U00002702-\\U000027B0\"\n",
        "#                                u\"\\U000024C2-\\U0001F251\"\n",
        "#                                \"]+\", flags=re.UNICODE)\n",
        "#     clean_text = emoji_pattern.sub(r'', text)  # Remove emojis from the text\n",
        "#     return clean_text\n",
        "\n",
        "# # Create a list to store cleaned texts\n",
        "# cleaned_texts = []\n",
        "\n",
        "# # Process each row in the DataFrame\n",
        "# for index, row in df1.iterrows():\n",
        "#     cleaned_text = remove_emojis(row['texts'])\n",
        "#     cleaned_texts.append(cleaned_text)\n",
        "\n",
        "# # Convert the list to a DataFrame\n",
        "# cleaned_texts_df = pd.DataFrame(cleaned_texts, columns=['texts'])\n",
        "\n",
        "# # Write the DataFrame to a CSV file\n",
        "# # cleaned_texts_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_text_data.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdLiJXsYyC_F",
        "outputId": "6d6fae07-6d93-4155-ab06-fa3aebddb768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   texts\n",
            "0                           Don't stop making videos bro\n",
            "1      Pinnadi irukiravan etho un pinadi parthutu irk...\n",
            "2                      Marana kalai.... super editing...\n",
            "3      à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...\n",
            "4                                  Sunderji very sad men\n",
            "...                                                  ...\n",
            "78887   Shakeela Amma à®¨à¯€à®™à¯à®• à®…à®µà®™à¯à®•à®³ à®¨à®²à¯à®²à®¾ handle à®ªà®£à¯à®±à¯€à®™à¯à®•\n",
            "78888        à®‡à®¨à¯à®¤ à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®à®©à¯à®©à¯‹à®Ÿ à®µà®¾à®´à¯à®¤à¯à®¤à¯à®•à¯à®•à®³à¯\n",
            "78889  Trichyb sathana..evalam oru pombala..panradhu ...\n",
            "78890              Shakkela amma va pakkanum pola irukku\n",
            "78891                                                 Hi\n",
            "\n",
            "[78892 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from demoji import replace\n",
        "\n",
        "# Read the CSV file\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_data.csv\")\n",
        "\n",
        "# Create a list to store cleaned texts\n",
        "cleaned_texts = []\n",
        "\n",
        "# Process each row in the DataFrame\n",
        "for index, row in df1.iterrows():\n",
        "    cleaned_text = replace(row['texts'])  # Replace emojis with empty strings\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  # Remove extra whitespaces\n",
        "    cleaned_texts.append(cleaned_text)\n",
        "\n",
        "# Convert the list to a DataFrame\n",
        "cleaned_texts_df = pd.DataFrame(cleaned_texts, columns=['texts'])\n",
        "\n",
        "# Remove rows with NaN values\n",
        "cleaned_texts_df.dropna(subset=['texts'], inplace=True)\n",
        "\n",
        "print(cleaned_texts_df)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "cleaned_texts_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_text_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJpkPjXOq3bU",
        "outputId": "b0540acf-471e-474b-8449-17bf5d16206f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "texts    \n",
            "Name: 5, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(cleaned_texts_df.iloc[5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzAfbaIYxVCT"
      },
      "source": [
        "### Cleantext method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywlgGgC_uK_8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from cleantext import clean\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/comments1.csv\")\n",
        "\n",
        "# Define a function to clean each cell in the DataFrame\n",
        "def clean_text(text):\n",
        "    return clean(text, no_emoji=True)\n",
        "\n",
        "# Apply the clean_text function to each cell in the DataFrame\n",
        "df = df.applymap(clean_text)\n",
        "\n",
        "# Write the cleaned DataFrame back to the CSV file\n",
        "df.to_csv(\"/content/drive/MyDrive/Misogyny/comments1.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qkimguNxZaZ"
      },
      "source": [
        "### re method1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "JrJcJpjZqzLj",
        "outputId": "29c55db8-4d2f-4c5c-e9b9-f4bff6e87e42"
      },
      "outputs": [
        {
          "ename": "ParserError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c62dfa5d49b5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import the CSV file into a Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Misogyny/comments.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Remove emojis from the text in the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Import the CSV file into a Pandas DataFrame\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Misogyny/comments.csv\")\n",
        "\n",
        "# Remove emojis from the text in the DataFrame\n",
        "def remove_emoji(text):\n",
        "    return re.sub(r\"[^\\w\\s]|\\n\", \" \", text)\n",
        "\n",
        "data[\"texts\"] = data[\"texts\"].apply(remove_emoji)\n",
        "\n",
        "# Write the DataFrame to the same CSV file\n",
        "data.to_csv(\"/content/drive/MyDrive/Misogyny/comments.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z56-zen596R0"
      },
      "source": [
        "### re method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL5gF_mGyDCQ"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def remove_emoji(string):\n",
        "  emoji_pattern = re.compile(\n",
        "      \"[\"\n",
        "      u\"\\U0001F600-\\U0001F64F\"\n",
        "      u\"\\U0001F300-\\U0001F5FF\"\n",
        "      u\"\\U0001F680-\\U0001F6FF\"\n",
        "      u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "      u\"\\U00002702-\\U000027B0\"\n",
        "      u\"\\U000024C2-\\U0001F251\"\n",
        "      \"]+\",\n",
        "      flags = re.UNICODE,\n",
        "\n",
        "  )\n",
        "  return emoji_pattern.sub(r\"\",string)\n",
        "\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/comments2.csv\")\n",
        "\n",
        "# Convert the texts column to a string\n",
        "df[\"texts\"] = df[\"texts\"].astype(\"str\")\n",
        "\n",
        "# Remove emojis from the comments column\n",
        "df[\"texts\"] = df[\"texts\"].apply(remove_emoji)\n",
        "\n",
        "# Write the cleaned DataFrame back to the CSV file\n",
        "df.to_csv(\"/content/drive/MyDrive/Misogyny/comments2.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiVyVtLcmmUz"
      },
      "source": [
        "pip install clean-text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0ndRfkwmmPy",
        "outputId": "f90c3412-e640-4a7b-a350-7cfc184300f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this sample text contains laughing emojis\n"
          ]
        }
      ],
      "source": [
        "#import clean function\n",
        "from cleantext import clean\n",
        "\n",
        "#provide string with emojis\n",
        "text = \"This sample text contains laughing emojis ğŸ˜€ ğŸ˜ƒ ğŸ˜„ ğŸ˜ ğŸ˜† ğŸ˜… ğŸ˜‚ ğŸ¤£\"\n",
        "\n",
        "#print text after removing the emojis from it\n",
        "print(clean(text, no_emoji=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FH2n-kEE4mOJ",
        "outputId": "65161fc7-5e00-463a-efd0-481662e6b92a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this sample text contains laughing emojis'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned = clean(text, no_emoji=True)\n",
        "cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdCkiWhkcCHZ"
      },
      "source": [
        "italicized text## Converting emojis to words using demoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkyUGDpxjfYE",
        "outputId": "7ce4d10c-afaf-4148-a2f0-63f6b8eff53c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting demoji\n",
            "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: demoji\n",
            "Successfully installed demoji-1.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install demoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qpr-w1csSsW",
        "outputId": "a2cdc210-0248-41e1-e3ba-b683238eaefe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                                  0\n",
            "0              0  Pinnadi irukiravan etho un pinadi parthutu irk...\n",
            "1              1  à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...\n",
            "2              2  Anti Muslim bjp party eppadi like panringe kus...\n",
            "3              3  August 15 .2022  à®‡à®©à¯à®±à¯ à®•à¯à®·à¯à®ªà¯‚ ...à®à®¨à¯à®¤ à®•à®Ÿà¯à®šà®¿à®¯à®¿à®²...\n",
            "4              4             Appo enna dash ku congress poi serndha\n",
            "...          ...                                                ...\n",
            "9404        9404  Please upload video about asha Lenin doctor ma...\n",
            "9405        9405  Dei scientific proof epdi da irukum eruma ella...\n",
            "9406        9406  Gh la nadakura tha unnala trol panni poda mudiuma\n",
            "9407        9407  Unglukulam nalllathu sonna puriyathu ellam eng...\n",
            "9408        9408  Oh Ahmed I thought you are doctor :face with t...\n",
            "\n",
            "[9409 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import demoji\n",
        "\n",
        "def deemojize_df(df, column=\"0\"):\n",
        "\n",
        "\n",
        "  if pd.api.types.is_string_dtype(df[column]):\n",
        "    df[column] = df[column].apply(lambda text: demoji.replace_with_desc(text))\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Misogyny/Misogyny/data1.csv')\n",
        "\n",
        "deemojized_df = deemojize_df(df, column=\"0\")\n",
        "deemojized_df.to_csv('/content/drive/MyDrive/Misogyny/Misogyny/data1.csv')\n",
        "print(deemojized_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hynmG9D9Cmat",
        "outputId": "24574ace-0258-4f8a-f793-776f2e8f45a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0    9409\n",
              "0             9409\n",
              "dtype: int64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsm04APzsmeC",
        "outputId": "9e0620fe-de47-4dcc-e78c-5abacaa3228f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "à®‡à®¤à¯†à®²à¯à®²à®¾à®®à¯ à®ªà®¾à®•à¯à®•à¯à®®à¯ à®ªà¯‹à®¤à¯  à®®à¯‹à®Ÿà®¿ à®°à¯Šà®®à¯à®ª à®ªà®¾à®µà®®à¯ à®¯à®¾à®†à®† :rolling on the floor laughing::rolling on the floor laughing::smiling face with hearts::smiling face with hearts::smiling face with hearts:\n"
          ]
        }
      ],
      "source": [
        "# text = deemojized_df.loc[12, \"0\"]\n",
        "\n",
        "# # Print the text\n",
        "# print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzInkBgzcOQp",
        "outputId": "fa6656ac-ff83-4b70-d21c-24dd22320971"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ğŸ¤¦': 'person facepalming', 'ğŸ¤”': 'thinking face'}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import demoji\n",
        "# text=\"Ada,ada,adaATRA SAKKA,ATRA SAKKA........ATRA SAKKAğŸ¤”ğŸ¤”ğŸ¤”ğŸ¤”ğŸ¤”ğŸ¤¦â€ğŸ¤¦â€ğŸ¤¦â€ğŸ¤¦â€ğŸ¤¦â€\"\n",
        "\n",
        "# demoji.findall(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0BaaCWAqMgL",
        "outputId": "063e9793-3f97-4dfa-aba3-723e48b3c9ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ada,ada,adaATRA SAKKA,ATRA SAKKA........ATRA SAKKA:thinking face::thinking face::thinking face::thinking face::thinking face::person facepalming:â€:person facepalming:â€:person facepalming:â€:person facepalming:â€:person facepalming:â€\n"
          ]
        }
      ],
      "source": [
        "# import demoji\n",
        "\n",
        "# text = \"Ada,ada,adaATRA SAKKA,ATRA SAKKA........ATRA SAKKAğŸ¤”ğŸ¤”ğŸ¤”ğŸ¤”ğŸ¤”ğŸ¤¦â€ğŸ¤¦â€ğŸ¤¦â€ğŸ¤¦â€ğŸ¤¦â€\"\n",
        "\n",
        "# deemojized_text = demoji.replace_with_desc(text)\n",
        "\n",
        "# print(deemojized_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhrOHdIEgI3f"
      },
      "source": [
        "## Removing emojis only line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUTmT84WgNAY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/orginal.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HmDJJ5efg7IF",
        "outputId": "28a05a3a-73ed-4ebe-cf12-25cc264c64b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b6b9ae55-3d0d-4dbf-a6fa-6552a085ba6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Don't stop making videos bro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pinnadi irukiravan etho un pinadi parthutu irk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Marana kalai.... â¤ğŸ˜‚ğŸ˜‚ğŸ˜‚ super editing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sunderji very sad men</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20568</th>\n",
              "      <td>Unglukulam nalllathu sonna puriyathu ellam eng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20569</th>\n",
              "      <td>Oh Ahmed I thought you are doctor ğŸ˜‚ Dai idiot ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20570</th>\n",
              "      <td>Waiting for this videoğŸ˜‚</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20571</th>\n",
              "      <td>Bangam naaaâ¤â¤â¤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20572</th>\n",
              "      <td>ğŸ˜‚</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20573 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6b9ae55-3d0d-4dbf-a6fa-6552a085ba6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-61914970-416f-439c-879f-3c4c648c16b8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-61914970-416f-439c-879f-3c4c648c16b8')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-61914970-416f-439c-879f-3c4c648c16b8 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6b9ae55-3d0d-4dbf-a6fa-6552a085ba6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6b9ae55-3d0d-4dbf-a6fa-6552a085ba6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                   texts\n",
              "0                           Don't stop making videos bro\n",
              "1      Pinnadi irukiravan etho un pinadi parthutu irk...\n",
              "2                 Marana kalai.... â¤ğŸ˜‚ğŸ˜‚ğŸ˜‚ super editing...\n",
              "3      à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...\n",
              "4                                  Sunderji very sad men\n",
              "...                                                  ...\n",
              "20568  Unglukulam nalllathu sonna puriyathu ellam eng...\n",
              "20569  Oh Ahmed I thought you are doctor ğŸ˜‚ Dai idiot ...\n",
              "20570                            Waiting for this videoğŸ˜‚\n",
              "20571                                     Bangam naaaâ¤â¤â¤\n",
              "20572                                                  ğŸ˜‚\n",
              "\n",
              "[20573 rows x 1 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOtZVA5ygsSl"
      },
      "outputs": [],
      "source": [
        "# Create a regular expression to match all emojis\n",
        "emoji_pattern = re.compile(r\"[^\\w\\s]\")\n",
        "\n",
        "# Use the replace() method to replace all emojis in the DataFrame with an empty string\n",
        "df[\"texts\"] = df[\"texts\"].replace(emoji_pattern, \"\")\n",
        "\n",
        "# Drop any rows where the text is empty\n",
        "df = df.dropna(subset=[\"texts\"])\n",
        "\n",
        "# Save the DataFrame to a new CSV file\n",
        "df.to_csv(\"/content/drive/MyDrive/Misogyny/new_orginal.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywYYgqhDau1"
      },
      "source": [
        "## Mergeing the csv files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeRZSvnmxQjm"
      },
      "source": [
        "### Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck6Vt1BCzLRh",
        "outputId": "5c338000-ea7a-41f2-d25d-69b7c3f3f435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   texts\n",
            "0                           Don't stop making videos bro\n",
            "1      Pinnadi irukiravan etho un pinadi parthutu irk...\n",
            "2                 Marana kalai.... â¤ğŸ˜‚ğŸ˜‚ğŸ˜‚ super editing...\n",
            "3      à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...\n",
            "4                                  Sunderji very sad men\n",
            "...                                                  ...\n",
            "78887   Shakeela Amma à®¨à¯€à®™à¯à®• à®…à®µà®™à¯à®•à®³ à®¨à®²à¯à®²à®¾ handle à®ªà®£à¯à®±à¯€à®™à¯à®•\n",
            "78888        à®‡à®¨à¯à®¤ à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®à®©à¯à®©à¯‹à®Ÿ à®µà®¾à®´à¯à®¤à¯à®¤à¯à®•à¯à®•à®³à¯\n",
            "78889  Trichyb sathana..evalam oru pombala..panradhu ...\n",
            "78890              Shakkela amma va pakkanum pola irukku\n",
            "78891                                                 Hi\n",
            "\n",
            "[78892 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/data1.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/data2.csv\")\n",
        "df3 = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/Modified_Toxic_comments.csv\")\n",
        "# Concatenate the DataFrames using the column name \"texts\" as the key\n",
        "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "# Write the merged DataFrame to a new CSV file\n",
        "merged_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_data.csv\", index=False)\n",
        "\n",
        "# Print the DataFrame to verify the column name change\n",
        "print(merged_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95TOSzLaWD2Z"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYKvnLnA7ttW"
      },
      "source": [
        "## Using Langdtect"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### langdetect"
      ],
      "metadata": {
        "id": "ebyhHuLM_j97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pRekeyACZM4",
        "outputId": "e6f38520-7e97-4500-c7d3-a8a5695e84e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=f82bf4d943ea679546333e749182c0256aa85f1780ca80c4918bbf73a0383bf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import langdetect\n",
        "import re\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_greater5text_data.csv\")\n"
      ],
      "metadata": {
        "id": "4RP4IUcO8wG6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "URlzWm7dB4AF",
        "outputId": "595f90f5-6cfb-4352-ad53-89f92b64b0ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   texts\n",
              "0      Pinnadi irukiravan etho un pinadi parthutu irk...\n",
              "1      à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...\n",
              "2      Anti Muslim bjp party eppadi like panringe kus...\n",
              "3      August 15 .2022 à®‡à®©à¯à®±à¯ à®•à¯à®·à¯à®ªà¯‚ ...à®à®¨à¯à®¤ à®•à®Ÿà¯à®šà®¿à®¯à®¿à®²à¯...\n",
              "4                 Appo enna dash ku congress poi serndha\n",
              "...                                                  ...\n",
              "43638     à®‡à®¨à¯à®¤ à®•à®¾à®²à®¤à¯à®¤à¯ à®ªà®šà®™à¯à®•à®³à¯ˆ à®¨à®¿à®©à¯ˆà®šà¯à®šà®¾ à®•à®·à¯à®Ÿà®®à®¾ à®‡à®°à¯à®•à¯à®•à¯ .\n",
              "43639   Shakeela Amma à®¨à¯€à®™à¯à®• à®…à®µà®™à¯à®•à®³ à®¨à®²à¯à®²à®¾ handle à®ªà®£à¯à®±à¯€à®™à¯à®•\n",
              "43640        à®‡à®¨à¯à®¤ à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®à®©à¯à®©à¯‹à®Ÿ à®µà®¾à®´à¯à®¤à¯à®¤à¯à®•à¯à®•à®³à¯\n",
              "43641  Trichyb sathana..evalam oru pombala..panradhu ...\n",
              "43642              Shakkela amma va pakkanum pola irukku\n",
              "\n",
              "[43643 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e252af1f-fb79-4b11-bc30-6c407b6247e4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pinnadi irukiravan etho un pinadi parthutu irk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Anti Muslim bjp party eppadi like panringe kus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>August 15 .2022 à®‡à®©à¯à®±à¯ à®•à¯à®·à¯à®ªà¯‚ ...à®à®¨à¯à®¤ à®•à®Ÿà¯à®šà®¿à®¯à®¿à®²à¯...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Appo enna dash ku congress poi serndha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43638</th>\n",
              "      <td>à®‡à®¨à¯à®¤ à®•à®¾à®²à®¤à¯à®¤à¯ à®ªà®šà®™à¯à®•à®³à¯ˆ à®¨à®¿à®©à¯ˆà®šà¯à®šà®¾ à®•à®·à¯à®Ÿà®®à®¾ à®‡à®°à¯à®•à¯à®•à¯ .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43639</th>\n",
              "      <td>Shakeela Amma à®¨à¯€à®™à¯à®• à®…à®µà®™à¯à®•à®³ à®¨à®²à¯à®²à®¾ handle à®ªà®£à¯à®±à¯€à®™à¯à®•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43640</th>\n",
              "      <td>à®‡à®¨à¯à®¤ à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®à®©à¯à®©à¯‹à®Ÿ à®µà®¾à®´à¯à®¤à¯à®¤à¯à®•à¯à®•à®³à¯</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43641</th>\n",
              "      <td>Trichyb sathana..evalam oru pombala..panradhu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43642</th>\n",
              "      <td>Shakkela amma va pakkanum pola irukku</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43643 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e252af1f-fb79-4b11-bc30-6c407b6247e4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e252af1f-fb79-4b11-bc30-6c407b6247e4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e252af1f-fb79-4b11-bc30-6c407b6247e4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-561ecfee-223b-4c6d-b8c2-2a667bde0484\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-561ecfee-223b-4c6d-b8c2-2a667bde0484')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-561ecfee-223b-4c6d-b8c2-2a667bde0484 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6bc7ccd6-cca9-4f53-84de-06e328fbd588\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6bc7ccd6-cca9-4f53-84de-06e328fbd588 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 43643,\n  \"fields\": [\n    {\n      \"column\": \"texts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42429,\n        \"samples\": [\n          \"If nanthini committed suicide you guys reason. Revenge taken by unknown brother .. you happy your family happy\",\n          \"True she doesn&#39;t sound like a Doctor. Just a content creator\",\n          \"\\u0ba8\\u0bc0 \\u0b8e\\u0bb2\\u0bcd\\u0bb2\\u0bbe\\u0bae\\u0bcd \\u0b92\\u0bb0\\u0bc1 \\u0baa\\u0bca\\u0ba3\\u0bcd\\u0ba3\\u0bbe \\u0ba4\\u0bbe\\u0baf\\u0bcd \\u0ba4\\u0ba8\\u0bcd\\u0ba4\\u0bc8 \\u0bb5\\u0b9a\\u0bcd\\u0b9a\\u0bc1\\u0b9f\\u0bcd\\u0b9f\\u0bc1 \\u0b87\\u0baa\\u0bcd\\u0baa\\u0bbf\\u0b9f\\u0bbf \\u0baa\\u0bc7\\u0b9a\\u0bc1\\u0bb1\\u0bbf\\u0baf\\u0bc7 \\u0bb5\\u0bc6\\u0b95\\u0bcd\\u0b95\\u0bae\\u0bbe \\u0b87\\u0bb2\\u0bcd\\u0bb2 \\u0ba8\\u0bbe\\u0baf\\u0bc7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ela8XVB1xf",
        "outputId": "e534cca9-fc02-48c1-8a95-8bfa37caa593"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "texts    43643\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import langdetect\n",
        "import re\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_greater5text_data.csv\")\n",
        "\n",
        "# Define a function to categorize the language of a text\n",
        "def categorize_language(text):\n",
        "    try:\n",
        "        lang = langdetect.detect(str(text))\n",
        "        if lang == \"en\":\n",
        "            return \"English\"\n",
        "        elif lang == \"ta\":\n",
        "            return \"Tamil\"\n",
        "        elif re.search(r'[\\u0B80-\\u0BFF]', text):\n",
        "            return \"others\"\n",
        "        else:\n",
        "            return \"others\"\n",
        "    except langdetect.lang_detect_exception.LangDetectException:\n",
        "        return \"others\"\n",
        "\n",
        "# Add a new column to the DataFrame with the categorized language of each text\n",
        "df[\"language\"] = df[\"texts\"].apply(categorize_language)\n",
        "\n",
        "# Save the categorized texts to separate DataFrames\n",
        "tamil_df = df[df[\"language\"] == \"Tamil\"]\n",
        "english_df = df[df[\"language\"] == \"English\"]\n",
        "others_df = df[df[\"language\"] == \"others\"]\n",
        "# unknown_df = df[df[\"language\"] == \"unknown\"]\n",
        "\n",
        "# Save the categorized DataFrame to a new CSV file\n",
        "# df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_greater5text_data_categorized.csv\", index=False)"
      ],
      "metadata": {
        "id": "FH66338TCM84"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import langdetect\n",
        "# import re\n",
        "\n",
        "# # Read the CSV file into a pandas DataFrame\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_greater5text_data.csv\")\n",
        "\n",
        "# # Define a function to categorize the language of a text\n",
        "# def categorize_language(text):\n",
        "#     try:\n",
        "#         lang = langdetect.detect(str(text))\n",
        "#         if lang == \"en\":\n",
        "#             return \"English\"\n",
        "#         elif lang == \"ta\":\n",
        "#             return \"Tamil\"\n",
        "#         elif re.search(r'[\\u0B80-\\u0BFF]', text.lower()):\n",
        "#             return \"others\"\n",
        "#         else:\n",
        "#             return \"others\"\n",
        "#     except langdetect.lang_detect_exception.LangDetectException:\n",
        "#         return \"others\"\n",
        "\n",
        "# # Create a new DataFrame with the categorized language of each text\n",
        "# df_categorized = pd.DataFrame(df[\"texts\"].apply(categorize_language).tolist(), columns=[\"language\"])\n",
        "\n",
        "# # Drop the language column from the original DataFrame\n",
        "# df = df.drop(\"texts\", axis=1)\n",
        "\n",
        "# # Join the original DataFrame with the categorized DataFrame\n",
        "# df_final = pd.concat([df, df_categorized], axis=1)\n",
        "\n",
        "# # Save the final DataFrame to a new CSV file\n",
        "# df_final.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/merged_greater5text_data_categorized.csv\", index=False)"
      ],
      "metadata": {
        "id": "gV_x2ExU4Chx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tamil_df = tamil_df.drop(columns=['language'])\n",
        "english_df = english_df.drop(columns=['language'])\n",
        "others_df = others_df.drop(columns=['language'])"
      ],
      "metadata": {
        "id": "ISu8dM1wEzi0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tamil_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOgK2WJHBhbZ",
        "outputId": "15eb06e7-37ee-4f87-e70c-1afb266f4dc5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   texts\n",
            "1      à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...\n",
            "3      August 15 .2022 à®‡à®©à¯à®±à¯ à®•à¯à®·à¯à®ªà¯‚ ...à®à®¨à¯à®¤ à®•à®Ÿà¯à®šà®¿à®¯à®¿à®²à¯...\n",
            "9          à®‡à®¤à¯†à®²à¯à®²à®¾à®®à¯ à®ªà®¾à®•à¯à®•à¯à®®à¯ à®ªà¯‹à®¤à¯ à®®à¯‹à®Ÿà®¿ à®°à¯Šà®®à¯à®ª à®ªà®¾à®µà®®à¯ à®¯à®¾à®†à®†\n",
            "12     à®‰à®©à®•à¯à®•à¯ à®ªà®£à®®à¯ à®•à¯Šà®Ÿà¯à®¤à¯à®¤ à®®à®¾à®¤à®¿à®°à®¿ à®à®™à¯à®•à®³à¯à®•à¯à®•à¯à®®à¯ à®•à¯à®Ÿà¯à®•à¯...\n",
            "15     à®†à®®à®¾ à®‡à®µà®¾...à®…à®µà®¾à®¤à®¾à®©.....à®•à®²à¯à®¯à®¾à®£à®¤à¯à®¤à¯à®•à¯à®•à¯ à®®à¯à®©à¯à®©à®¾à®² à®†à®£...\n",
            "...                                                  ...\n",
            "43636  à®šà®¾à®¤à®©à®¾ à®†à®©à¯à®Ÿà¯à®Ÿà®¿à®•à¯à®•à¯ à®‡à®¨à¯à®¤ à®µà®°à¯à®Ÿà®¤à¯à®¤à®¿à®©à¯ à®ªà®¤à¯à®®à®ªà¯‚à®šà®©à¯ à®µà®¿...\n",
            "43637  à®šà®¤à®¾à®£à®¾ à®¤à¯‡à®µà®¿à®Ÿà®¿à®¯à®¾ à®šà®¾à®°à¯à®ªà®¾à®• à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®µà®¾à®´à¯à®¤...\n",
            "43638     à®‡à®¨à¯à®¤ à®•à®¾à®²à®¤à¯à®¤à¯ à®ªà®šà®™à¯à®•à®³à¯ˆ à®¨à®¿à®©à¯ˆà®šà¯à®šà®¾ à®•à®·à¯à®Ÿà®®à®¾ à®‡à®°à¯à®•à¯à®•à¯ .\n",
            "43639   Shakeela Amma à®¨à¯€à®™à¯à®• à®…à®µà®™à¯à®•à®³ à®¨à®²à¯à®²à®¾ handle à®ªà®£à¯à®±à¯€à®™à¯à®•\n",
            "43640        à®‡à®¨à¯à®¤ à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®à®©à¯à®©à¯‹à®Ÿ à®µà®¾à®´à¯à®¤à¯à®¤à¯à®•à¯à®•à®³à¯\n",
            "\n",
            "[8975 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(english_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSjaXXGUBphc",
        "outputId": "e9c3d802-2df2-4a1f-92f0-951673500945"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   texts\n",
            "8      Firstly, i don't trust political leaders jumps...\n",
            "10     Sathyama mudila semma edit . I know how much e...\n",
            "11       Where is my akka, after election no news of her\n",
            "14     After Election Defeat where's .Kushboo madam. ...\n",
            "16     Ma'm, you were with the Congress, right? If yo...\n",
            "...                                                  ...\n",
            "43608  Ethuku pesave therila etho etho pesuthu paithiyam\n",
            "43613  We think these artist are only vulgar, exposin...\n",
            "43615  Shakeela vara ena vela pakranu unaku theritha....\n",
            "43618  What happened to the gallata channel,<br>Do we...\n",
            "43635  Amutha Amma interview poduga.. nega already av...\n",
            "\n",
            "[15128 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(others_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkOAxtOwBpXz",
        "outputId": "eefe230a-4c0e-4361-a710-62bb8b2fe0e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   texts\n",
            "0      Pinnadi irukiravan etho un pinadi parthutu irk...\n",
            "2      Anti Muslim bjp party eppadi like panringe kus...\n",
            "4                 Appo enna dash ku congress poi serndha\n",
            "5      Losu kudi kandaraoli punda kudi anna janmam da...\n",
            "6      Vetkam maanan illa, kalla ottu mattum than tha...\n",
            "...                                                  ...\n",
            "43631          Amma va ninaikurava ipti aduviya asingama\n",
            "43632  Tamil Nadu la ena problm poitu iruku Ungaluku ...\n",
            "43634  Nattuku romba mukiyamana interview rendu thy v...\n",
            "43641  Trichyb sathana..evalam oru pombala..panradhu ...\n",
            "43642              Shakkela amma va pakkanum pola irukku\n",
            "\n",
            "[19540 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8WXECmNEyhh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tamil_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/tamil_texts.csv\", index=False)\n",
        "english_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/english_texts.csv\", index=False)\n",
        "others_df.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/other_texts.csv\", index=False)"
      ],
      "metadata": {
        "id": "UZaCGqmP9-V5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/tamil_texts.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/english_texts.csv\")\n",
        "df3 = pd.read_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/other_texts.csv\")"
      ],
      "metadata": {
        "id": "6LPRzoch8bOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the first column (numbering)\n",
        "# df1 = df1.drop(df1.columns[0], axis=1)\n",
        "\n",
        "# Remove the language column\n",
        "df1 = df1.drop(columns=['language'])"
      ],
      "metadata": {
        "id": "dxxyn-EIMV6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the first column (numbering)\n",
        "# df2 = df2.drop(df2.columns[0], axis=1)\n",
        "\n",
        "# Remove the language column\n",
        "df2 = df2.drop(columns=['language'])"
      ],
      "metadata": {
        "id": "zkXWMx8ONHfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the first column (numbering)\n",
        "# df3 = df3.drop(df3.columns[0], axis=1)\n",
        "\n",
        "# Remove the language column\n",
        "df3 = df3.drop(columns=['language'])"
      ],
      "metadata": {
        "id": "YxK4jbpZNHaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot2WOJnUNHWF",
        "outputId": "7497d7e4-a4ca-492e-e5d0-a6aaac266471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  texts\n",
            "0     à®¤à®¾à®®à®°à¯ˆ à®®à®²à®°à¯à®•à®¿à®±à®¤à¯ à®‡à®²à¯à®²à¯ˆà®¯à¯‹ à®¨à¯€ à®ªà®²à®®à¯à®±à¯ˆ à®®.......à¯à®¤à¯ ...\n",
            "1     August 15 .2022 à®‡à®©à¯à®±à¯ à®•à¯à®·à¯à®ªà¯‚ ...à®à®¨à¯à®¤ à®•à®Ÿà¯à®šà®¿à®¯à®¿à®²à¯...\n",
            "2         à®‡à®¤à¯†à®²à¯à®²à®¾à®®à¯ à®ªà®¾à®•à¯à®•à¯à®®à¯ à®ªà¯‹à®¤à¯ à®®à¯‹à®Ÿà®¿ à®°à¯Šà®®à¯à®ª à®ªà®¾à®µà®®à¯ à®¯à®¾à®†à®†\n",
            "3     à®‰à®©à®•à¯à®•à¯ à®ªà®£à®®à¯ à®•à¯Šà®Ÿà¯à®¤à¯à®¤ à®®à®¾à®¤à®¿à®°à®¿ à®à®™à¯à®•à®³à¯à®•à¯à®•à¯à®®à¯ à®•à¯à®Ÿà¯à®•à¯...\n",
            "4     à®†à®®à®¾ à®‡à®µà®¾...à®…à®µà®¾à®¤à®¾à®©.....à®•à®²à¯à®¯à®¾à®£à®¤à¯à®¤à¯à®•à¯à®•à¯ à®®à¯à®©à¯à®©à®¾à®² à®†à®£...\n",
            "...                                                 ...\n",
            "8970  à®šà®¾à®¤à®©à®¾ à®†à®©à¯à®Ÿà¯à®Ÿà®¿à®•à¯à®•à¯ à®‡à®¨à¯à®¤ à®µà®°à¯à®Ÿà®¤à¯à®¤à®¿à®©à¯ à®ªà®¤à¯à®®à®ªà¯‚à®šà®©à¯ à®µà®¿...\n",
            "8971  à®šà®¤à®¾à®£à®¾ à®¤à¯‡à®µà®¿à®Ÿà®¿à®¯à®¾ à®šà®¾à®°à¯à®ªà®¾à®• à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®µà®¾à®´à¯à®¤...\n",
            "8972     à®‡à®¨à¯à®¤ à®•à®¾à®²à®¤à¯à®¤à¯ à®ªà®šà®™à¯à®•à®³à¯ˆ à®¨à®¿à®©à¯ˆà®šà¯à®šà®¾ à®•à®·à¯à®Ÿà®®à®¾ à®‡à®°à¯à®•à¯à®•à¯ .\n",
            "8973   Shakeela Amma à®¨à¯€à®™à¯à®• à®…à®µà®™à¯à®•à®³ à®¨à®²à¯à®²à®¾ handle à®ªà®£à¯à®±à¯€à®™à¯à®•\n",
            "8974        à®‡à®¨à¯à®¤ à®µà¯€à®Ÿà®¿à®¯à¯‹ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®± à®à®©à¯à®©à¯‹à®Ÿ à®µà®¾à®´à¯à®¤à¯à®¤à¯à®•à¯à®•à®³à¯\n",
            "\n",
            "[8975 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WVKTrFS8-Gb",
        "outputId": "cffcfaf2-9dea-46f0-bc68-ce5ca3f660c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   texts\n",
            "0      Firstly, i don't trust political leaders jumps...\n",
            "1      Sathyama mudila semma edit . I know how much e...\n",
            "2        Where is my akka, after election no news of her\n",
            "3      After Election Defeat where's .Kushboo madam. ...\n",
            "4      Ma'm, you were with the Congress, right? If yo...\n",
            "...                                                  ...\n",
            "15055  à®Šà®°à¯à®² iruka thevidya yellam wachi interview pan...\n",
            "15056  We think these artist are only vulgar, exposin...\n",
            "15057  Shakeela vara ena vela pakranu unaku theritha....\n",
            "15058  What happened to the gallata channel,<br>Do we...\n",
            "15059  Amutha Amma interview poduga.. nega already av...\n",
            "\n",
            "[15060 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qznOPHhY9Nhk",
        "outputId": "123186bd-59d4-4401-b11c-9d222efcc699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 texts\n",
            "0    à®‡à®µ peuratha patha sirippa à®…à®Ÿà®•à¯à®• à®®à¯à®Ÿà®¿à®¯à®²à¯ˆ Troll ...\n",
            "1    Bjp admk pmk à®à®²à¯à®²à®¾à®®à¯ enna enna panaga à®©à¯ nan m...\n",
            "2         @rubytalkies5686 mid night masala à®ªà®¾à®°à¯ sanki\n",
            "3    Ponathadavi congress kku ippadithaan sonna. Ip...\n",
            "4      Ipdi solli Jayalalithaa va maaralam nu à®†à®šà¯ˆ pola\n",
            "..                                                 ...\n",
            "167  Sadhana ....ilakiyaa video pathutu vandhurupa ...\n",
            "168  Gotha yaara neenga.....<br>Munnadiyellam hard ...\n",
            "169  Avan à®¤à®¾à®¯à¯ à®®à®¾à®®à®¾ illa..unnakum avan than brocker...\n",
            "170  Ration rice free thana de..atha wanaga yen kas...\n",
            "171  Yen da nayanthara va vida iva à®à®©à¯à®©à®¤à¯à®¤ à®•à¯‡à®µà®²à®®à®¾ k...\n",
            "\n",
            "[172 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/tamil_texts.csv\", index=False)\n",
        "df2.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/english_texts.csv\", index=False)\n",
        "df3.to_csv(\"/content/drive/MyDrive/Misogyny/Misogyny/other_texts.csv\", index=False)"
      ],
      "metadata": {
        "id": "6MdZj-Nm9OqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNeZJAse9Zaj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2wGj6O1LclmX",
        "CAVK-JRVyM2X",
        "qOyq83vZyun1",
        "FzAfbaIYxVCT",
        "9qkimguNxZaZ",
        "Z56-zen596R0",
        "fdCkiWhkcCHZ",
        "xhrOHdIEgI3f",
        "K7JHD7dAnVLJ"
      ],
      "provenance": [],
      "mount_file_id": "1JmQr0V0AZ8Ob_eB1snoo0ys8m9dRN0N8",
      "authorship_tag": "ABX9TyMQhyIMaYu2oF/9A9fVK8iI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}